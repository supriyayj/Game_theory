import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow
!pip install tensorflow

import os
#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.datasets import mnist
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.backend import image_data_format
from keras.models import Sequential
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from keras.models import Sequential
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from keras.layers import Dense
from keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D
from keras.layers import AvgPool2D, MaxPooling2D, Dropout, Flatten, BatchNormalization
from keras.constraints import maxnorm
import matplotlib.pyplot as plt
import numpy as np
import copy
import random
import sys
import glob
import keras
import cv2
import csv
import time
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint

from google.colab import drive
drive.mount('/content/drive')

X,y1, y = [], [],[]
train_labels = {
    "fire":0,"nofire":1
}
x_train=list()
y_train=list()
fire = glob.glob('/content/Forest Fire Dataset/Training/fire/*.jpg')
nfire =glob.glob('/content/Forest Fire Dataset/Training/nofire/*.jpg')
print("values"+str(len(nfire)))
for i in fire:
    print("i value",i)
    img = cv2.imread(str(i)) # Reading the image
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (150, 150))
    img=np.float32(img)
    X.append(img)
            #y.append(train_labels[label])
    #img=cv2.imread(i,1)
    #img=cv2.resize(img,(150,150))
    #img=np.float32(img)
    #img/=255.0
    #img = img.reshape(150, 150, 3)
    #X.append(img)
    y.append(1)

print("X values fire"+str(len(X)))
#print("i values"+str(i))
for j in nfire:
    img = cv2.imread(str(j)) # Reading the image
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (150, 150))

    #img=cv2.imread(j,1)
    #img=cv2.resize(img,(150,150))
    img=np.float32(img)
    X.append(img)
    #img/=255.0
    #img = img.reshape(150, 150, 3)
    #print("image"+str(img.size))
    #X.append(img)
    y.append(0)
print("j values"+str(j))
print("X values nfire"+str(len(X)))
print("y values"+str(y))
print("X values"+str(len(X)))
#x_train=np.asarray(x_train)
#y_train=np.asarray(y_train)
#y=to_categorical(y)
#x_train.shape
#y_train.shape


firel = glob.glob('/content/Forest Fire Dataset/Testing/fire/*.jpg')
nfirel=glob.glob('/content/Forest Fire Dataset/Testing/nofire/*.jpg')
x_test=list()
y_test=list()
for i in firel:
    img = cv2.imread(str(i)) # Reading the image
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (150, 150))
    #img=cv2.imread(i,1)
    #img=cv2.resize(img,(150,150))
    #img=np.float32(img)
    #img/=255.0
    #img = img.reshape(150, 150, 3)
    #img=img.tolist()
    img=np.float32(img)
    X.append(img)
    y.append(1)
print("X values fire"+str(len(X)))
for j in nfirel:
    img = cv2.imread(str(j)) # Reading the image
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (150, 150))
    #img=cv2.imread(i,1)
    #img=cv2.resize(img,(150,150))
    #img=np.float32(img)
    #img/=255.0
    #img = img.reshape(150, 150, 3)
    #img=img.tolist()
    img=np.float32(img)
    X.append(img)
    y.append(0)
#x_test=np.asarray(x_test)
#y_test=np.asarray(y_test)
y=to_categorical(y)
#x_test.shape
#y_test.shape
plt.show(X)
print("y values"+str(len(y)))
print("X values fire"+str(len(X)))

import numpy
y3=[]
X_samp = numpy.asarray(X)
print(X_samp.shape)
#X_samp = (X_samp/255)
#y3=y1+y2
y1n = np.asarray(y1).astype('float32').reshape((-1,1))
y1l = np.asarray(y).astype('float32').reshape((-1,1))

#print(y_samp[56])
#X_samp = (X_samp/255)
#le = LabelEncoder()
#le.fit(y)
#y = le.transform(y)
#y = LabelEncoder().fit_transform(y).reshape(-1, 1).astype("float")
y_samp = numpy.asarray(y)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_samp, y_samp, test_size=0.2)
print("X_train",X_train.shape)
print("y_train",y_train.shape)
print("X_test",X_test.shape)
print("y_test",y_test.shape)
print("X_train len",len(X_train))
print("y_train",y_train.shape)
print("X_test",X_test.shape)
print("y_test",y_test.shape)
plt.imshow(X_samp[23])

serverhist1={
    "loss": list(),
    "accuracy": list(),
    "payoff": list()
    }
client_payoff = []
client_number = []
from sklearn.ensemble import RandomForestClassifier
def game_theory_federated_learning(X_train, y_train, X_test, y_test, num_clients, num_epochs, batch_size, lr):
    print("X_train len",len(X_train))
    print("y_train len",len(y_train))
    print("X_train len",len(X_test))
    print("y_train len",len(y_test))
    #num_classes = y_train.shape[0]
    #input_shape = X_train.shape[1:]
    model_list = []
    for i in range(num_clients):
        #model = RandomForestClassifier(max_depth=6, n_estimators=10, random_state=4686)
        #model.fit(X_train, y_train)

        #from sklearn.metrics import classification_report
        #y_pred = model.predict(X_test)
        #print(classification_report(y_test, y_pred))

        model=tf.keras.Sequential([
            tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)),
            tf.keras.layers.MaxPool2D(2,2),
            tf.keras.layers.Conv2D(64,(3,3),activation='relu'),
            tf.keras.layers.MaxPool2D(2,2),
       #model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))
       #model.add(keras.layers.MaxPool2D(2,2))
            tf.keras.layers.Conv2D(128,(3,3),activation='relu'),
            tf.keras.layers.MaxPool2D(2,2),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(512,activation='relu'),
            tf.keras.layers.Dense(2,activation='sigmoid'),

        ])
        #model.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])
        #tf.config.run_functions_eagerly(True)
        model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])
        model_list.append(model)

    # Train each client model for a fixed number of epochs
    for i in range(num_clients):
        print("----------------CLIENT " + str(i) +"-------------------------")
        model_list[i].fit(X_train[i*(len(X_train)//num_clients):(i+1)*(len(X_train)//num_clients)],
                          y_train[i*(len(X_train)//num_clients):(i+1)*(len(X_train)//num_clients)],
                          epochs=num_epochs, batch_size=batch_size,validation_data=(X_test, y_test))
        #h=model_list[i].evaluate(X_test,y_test)
        #serverhist1['loss'].append(h[1])
        #serverhist1['accuracy'].append(h[0])
        #model_size = sum(np.prod(layer.get_weights()[0].shape) for layer in model.layers)
        #print("Model size:", model_size * 4, "bytes")  # assuming 32-bit floats
    #for i in range(num_clients):
        # Train the client model and transmit the updated model weights back to the server

    # Calculate the size of the updated model weights from each client
      #updated_weights_size = sum(sum(abs(layer.get_weights()[i] - global_weights[i])) for i in range(len(global_weights)))
      #print("Updated weights size:", updated_weights_size * 4, "bytes")  # assuming 32-bit floats

    #for i in range(num_clients):
        # Transmit the new global model weights to the client i

    # Evaluate the new global model
    #_, global_accuracy = model.evaluate(X_test, y_test, verbose=0)

    # Calculate the total communication cost
      #communication_cost = (model_size + updated_weights_size) * num_clients
      #print("Communication cost:", communication_cost, "bytes")

    # Calculate each client's accuracy on the test set
    client_accuracies = []
    for i in range(num_clients):
        _, accuracy = model_list[i].evaluate(X_test, y_test, verbose=0)
        client_accuracies.append(accuracy)

    # Calculate each client's payoff
    client_payoffs = []
    for i in range(num_clients):
        print("----------------CLIENT " + str(i) +"-------------------------")
        payoff = client_accuracies[i] - np.mean(client_accuracies)
        print("----------------PAYOFF " + str(i) +"-------------------------"+ str(payoff))
        client_payoffs.append(payoff)
        client_payoff.append(payoff)
        client_number.append(i)
        h=model_list[i].evaluate(X_test,y_test)
        serverhist1['loss'].append(h[1])
        serverhist1['accuracy'].append(h[0])
        serverhist1['payoff'].append(client_payoffs[i])
    model.summary()
    # Update each client's model based on their payoff
    for i in range(num_clients):
        #print("-----Num of Clients"+num_clients)
        for layer in model_list[i].layers:
            layer.set_weights(layer.get_weights() + lr * client_payoffs[i])
            print("weights of the layers"+str(layer.get_weights()))

    # Aggregate the updated models to form the new global model
    global_weights = np.array(model_list[0].get_weights())
    for i in range(1, num_clients):
        global_weights += np.array(model_list[i].get_weights())
    new_global_weights = global_weights / num_clients
    #h=model_list[i].evaluate(X_test,y_test)
    #serverhist1['loss'].append(h[1])
    #serverhist1['accuracy'].append(h[0])
    # Update the global model
    for i in range(num_clients):
        model_list[i].set_weights(new_global_weights)

    # Evaluate the new global model
    _, global_accuracy = model_list[0].evaluate(X_test, y_test, verbose=0)
    return global_accuracy
    #t the hyperparameters
num_clients = 10
num_epochs = 10
batch_size = 32
lr = 0.1

# Run the game-theoretic federated learning algorithm
global_accuracy = game_theory_federated_learning(X_train, y_train, X_test, y_test, num_clients, num_epochs, batch_size, lr)
print("Global accuracy:", global_accuracy)
#server_model = game_theory_federated_learning(X_train, y_train, X_test, y_test, num_clients, num_epochs, batch_size, lr)
print(" \t\t\tFL")
print("Round\tAccuracy\t\tLoss\t\tPayoff")
for i in range(num_epochs):
  print(str(serverhist1['loss'][i])+"\t"+str(serverhist1['accuracy'][i])+"\t"+str(client_payoff[i]))

